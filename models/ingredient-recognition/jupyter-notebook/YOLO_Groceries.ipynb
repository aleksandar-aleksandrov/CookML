{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO-Groceries.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RzNWD_0Dy_1Z",
        "OCS7RPmozE5H",
        "fZzDS2G_zIuQ",
        "ioJaMQSOzOiw",
        "--5wqBV8J-OG",
        "vJDZ7CyhzWkI",
        "0hAWgbZGfo3-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzNWD_0Dy_1Z",
        "colab_type": "text"
      },
      "source": [
        "#Prepare the Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNuzY6kSy8XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the dataset\n",
        "!wget https://github.com/aleksandar-aleksandrov/groceries-object-detection-dataset/archive/master.zip\n",
        "\n",
        "# Download annotations\n",
        "!7z x -y master.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP03RWVpc0il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd groceries-object-detection-dataset-master\n",
        "!ls\n",
        "!ls groceries-object-detection-dataset-master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDO21stNNm2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjhJcgDLzgl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from pathlib import Path\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Reshape, Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms6uqbtFIfqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define global Variables\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "TRAIN_DATASET_SIZE = 4960\n",
        "CHANNELS = 3\n",
        "EPOCHS = 800\n",
        "\n",
        "# The image is divided into 4x4 grid of cells\n",
        "S = 4\n",
        "# Amount of Bounding Boxes. Each BB is a tuple of type (x, y, w, h, confidence)\n",
        "B = 1\n",
        "B_SIZE = 5\n",
        "\n",
        "# Class Labels\n",
        "CLASS_LABELS = [\n",
        "    'beans', 'cake', 'candy', 'cereal', 'chips', 'chocolate', 'coffee', 'corn',\n",
        "    'fish', 'flour', 'honey', 'jam', 'juice', 'milk', 'nuts', 'oil', 'pasta',\n",
        "    'rice', 'soda', 'spices', 'sugar', 'tea', 'tomato_sauce', 'vinegar', 'water'\n",
        "]\n",
        "\n",
        "C = len(CLASS_LABELS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCS7RPmozE5H",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcfCMCTGot5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_objects(file):\n",
        "    root = ET.parse(file).getroot()\n",
        "\n",
        "    objs = []\n",
        "    for child in root.iter('object'):\n",
        "        obj = {}\n",
        "        obj['class'] = child.find('name').text\n",
        "        \n",
        "        bndbox = child.find('bndbox')\n",
        "        obj['xmax'] = float(bndbox.find('xmax').text)\n",
        "        obj['xmin'] = float(bndbox.find('xmin').text)\n",
        "        obj['ymax'] = float(bndbox.find('ymax').text)\n",
        "        obj['ymin'] = float(bndbox.find('ymin').text)\n",
        "\n",
        "        objs.append(obj)\n",
        "\n",
        "    return objs\n",
        "\n",
        "def load_dataset(dataset_size):\n",
        "    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    X = np.zeros((dataset_size, IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
        "    Y = np.zeros((dataset_size, S, S, B, 5 + C))\n",
        "\n",
        "    index = 0\n",
        "    labels_path = Path(f'/content/groceries-object-detection-dataset-master/dataset/annotations')\n",
        "    img_path = Path(f'/content/groceries-object-detection-dataset-master/dataset/images')\n",
        "\n",
        "    for class_dir in labels_path.iterdir():\n",
        "        for file in class_dir.iterdir():\n",
        "            objects = get_objects(file)\n",
        "            array = np.zeros((S, S, B, 5 + C))\n",
        "            \n",
        "            for obj in objects:\n",
        "                confidence = 1\n",
        "\n",
        "                center_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "                center_x = center_x / (IMG_HEIGHT / S)\n",
        "                x = center_x - np.floor(center_x)\n",
        "                grid_x = int(np.floor(center_x))\n",
        "\n",
        "                center_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "                center_y = center_y / (IMG_WIDTH / S)\n",
        "                y = center_y - np.floor(center_y)\n",
        "                grid_y = int(np.floor(center_y))\n",
        "\n",
        "                w = (obj['xmax'] - obj['xmin']) / IMG_HEIGHT\n",
        "                h = (obj['ymax'] - obj['ymin']) / IMG_WIDTH\n",
        "\n",
        "                class_array = [0.] * C\n",
        "                class_array[CLASS_LABELS.index(obj['class'])] = 1.\n",
        "\n",
        "                array[grid_x, grid_y, 0] = [x] + [y] + [w] + [h] + [confidence] + class_array\n",
        "            img_paths = str(file).replace('annotations', 'images').replace('.xml', '.png')\n",
        "            img = tf.keras.preprocessing.image.load_img(img_paths)\n",
        "            img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            X[index] = img_arr\n",
        "            Y[index] = array\n",
        "            index += 1\n",
        "\n",
        "            if index >= dataset_size:\n",
        "              break\n",
        "        if index >= dataset_size:\n",
        "              break\n",
        "    Y = np.asarray(Y).astype('float32')\n",
        "    return image_generator.flow(X, Y, batch_size=BATCH_SIZE)\n",
        "                    \n",
        "def show_batch(dataset):\n",
        "        image_batch, label_batch = next(dataset)\n",
        "        image_batch = list(image_batch)\n",
        "        label_batch = list(label_batch)\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for n in range(4):\n",
        "            ax = plt.subplot(2, 2, n + 1)\n",
        "            plt.imshow(image_batch[n])\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "train_dataset = load_dataset(TRAIN_DATASET_SIZE)\n",
        "show_batch(train_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZzDS2G_zIuQ",
        "colab_type": "text"
      },
      "source": [
        "# Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoKwjA5-1KZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_base_model():\n",
        "    return tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), classes=C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yGSFqOM1dlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freeze_trained_layers(model):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable=False\n",
        "        \n",
        "    return model\n",
        "\n",
        "def get_yolo_model():\n",
        "    base_model = get_base_model()\n",
        "    base_model = freeze_trained_layers(base_model)\n",
        "\n",
        "    x = Conv2D(B * (5 + C), (3,3), strides=(2,2), padding='same', kernel_initializer='lecun_normal')(base_model.output)\n",
        "    x = Conv2D(B * (5 + C), (1,1), strides=(1,1), padding='same', kernel_initializer='lecun_normal')(x)\n",
        "    x = Reshape((S, S, B, 5 + C))(x)\n",
        "\n",
        "    return Model(base_model.input, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioJaMQSOzOiw",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YYqeBKKQduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_loss(y_true, y_pred):\n",
        "    mask_shape = tf.shape(y_true)[:4]\n",
        "        \n",
        "    cell_x = tf.cast(tf.reshape(tf.tile(tf.range(S), [S]), (1, S, S, 1, 1)), dtype=tf.float32)\n",
        "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, B, 1])\n",
        "    coord_mask = tf.zeros(mask_shape)\n",
        "    conf_mask  = tf.zeros(mask_shape)\n",
        "    class_mask = tf.zeros(mask_shape)\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust prediction\n",
        "    \"\"\"\n",
        "    ### adjust x and y      \n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "    \n",
        "    ### adjust w and h\n",
        "    pred_box_wh = tf.sigmoid(y_pred[..., 2:4])\n",
        "    \n",
        "    ### adjust confidence\n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    pred_box_class = y_pred[..., 5:]\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust ground truth\n",
        "    \"\"\"\n",
        "    ### adjust x and y\n",
        "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "    \n",
        "    ### adjust w and h\n",
        "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "    \n",
        "    ### adjust confidence\n",
        "    true_wh_half = true_box_wh / 2.\n",
        "    true_mins    = true_box_xy - true_wh_half\n",
        "    true_maxes   = true_box_xy + true_wh_half\n",
        "    \n",
        "    pred_wh_half = pred_box_wh / 2.\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "    #iou_scores = 1\n",
        "\n",
        "    true_box_conf = iou_scores * y_true[..., 4]\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "    \n",
        "    \"\"\"\n",
        "    Determine the masks\n",
        "    \"\"\"\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "    \n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1)\n",
        "    \n",
        "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "    true_xy = tf.expand_dims(true_box_xy, 4)\n",
        "    true_wh = tf.expand_dims(true_box_wh, 4)\n",
        "    \n",
        "    true_wh_half = true_wh / 2.\n",
        "    true_mins    = true_wh_half\n",
        "    true_maxes   = true_wh_half\n",
        "    \n",
        "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "    \n",
        "    pred_wh_half = pred_wh / 2.\n",
        "    pred_mins    = pred_xy - pred_wh_half\n",
        "    pred_maxes   = pred_xy + pred_wh_half    \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "    \n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "    conf_mask = conf_mask + tf.cast(best_ious < 0.6,dtype=tf.float32) * (1 - y_true[..., 4]) * 0.5\n",
        "    \n",
        "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "    conf_mask = conf_mask + y_true[..., 4] * 0.5\n",
        "    \n",
        "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
        "    class_wt = tf.ones(C)\n",
        "    class_mask = y_true[..., 4] * tf.gather(class_wt, true_box_class) * 0.5       \n",
        "    \n",
        "    \"\"\"\n",
        "    Finalize the loss\n",
        "    \"\"\"\n",
        "    nb_coord_box = tf.reduce_sum(tf.cast(coord_mask > 0.0,dtype=tf.float32))\n",
        "    nb_conf_box  = tf.reduce_sum(tf.cast(conf_mask  > 0.0, dtype=tf.float32))\n",
        "    nb_class_box = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32))\n",
        "    \n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask) / (nb_conf_box + 1e-6) / 2.\n",
        "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
        "    \n",
        "    loss = loss_xy + loss_wh + loss_conf + loss_class * 10\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwnUdck5sT0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_yolo_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHUKTXZgJjCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=SGD(lr=2e-4, momentum=0.9), loss=yolo_loss)\n",
        "\n",
        "history = model.fit(train_dataset, epochs = EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--5wqBV8J-OG",
        "colab_type": "text"
      },
      "source": [
        "# Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZp6l6mKBp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to visualize training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(history):\n",
        "    training_loss = history.history['loss']\n",
        "    epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "    plt.plot(epoch_count, training_loss, 'r--')\n",
        "    plt.legend(['Training Loss'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJDZ7CyhzWkI",
        "colab_type": "text"
      },
      "source": [
        "#Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JBRfu4oPqQ_B",
        "colab": {}
      },
      "source": [
        "# Convert to TFLite Format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vL5XOH4FwB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download tflite model\n",
        "files.download('/content/converted_model.tflite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPm-iUUsOSU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the trained model\n",
        "tf.saved_model.save(model, \"/content/model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6KIL8m9OuAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/model.zip /content/model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLYAaIFPrCqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--ni_FnnrC8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the loss\n",
        "open(\"/content/history.txt\", \"w\").write(str(history.history['loss']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnHrDXuafTjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/history.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hAWgbZGfo3-",
        "colab_type": "text"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xzHRDB1frTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "image_batch, label_batch = next(train_dataset)\n",
        "image_batch = list(image_batch)\n",
        "label_batch = list(label_batch)\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def get_label_bounding_boxes(label):\n",
        "    x_a, y_a, w_a, h_a = 0, 0, 0, 0\n",
        "    xs, ys, ws, hs = [], [], [], []\n",
        "    for i in range(S):\n",
        "        for j in range(S):\n",
        "            for b in range(B):\n",
        "                bb_box = label[i][j][b]\n",
        "                \n",
        "                if bb_box[0] != 0:\n",
        "                    x_a = bb_box[0]\n",
        "                    y_a = bb_box[1]\n",
        "                    w_a = bb_box[2] * IMG_WIDTH\n",
        "                    h_a = bb_box[3] * IMG_HEIGHT\n",
        "                    \n",
        "                    x_a = (i + x_a)*56 - w_a / 2\n",
        "                    y_a = (j + y_a)*56 - h_a / 2\n",
        "                    xs.append(x_a)\n",
        "                    ys.append(y_a)\n",
        "                    ws.append(w_a)\n",
        "                    hs.append(h_a)\n",
        "    return xs, ys, ws, hs\n",
        "  \n",
        "def get_predicted_bounding_boxes(result):\n",
        "  bb_boxes = []\n",
        "  for i in range(S):\n",
        "    for j in range(S):\n",
        "      for b in range(B):\n",
        "        bb_box = result[0][i][j][b]\n",
        "        \n",
        "        x = sigmoid(bb_box[0])\n",
        "        y = sigmoid(bb_box[1])\n",
        "        w = sigmoid(bb_box[2])\n",
        "        h = sigmoid(bb_box[3])\n",
        "\n",
        "        confidence = sigmoid(bb_box[4])\n",
        "\n",
        "        max_class = 0\n",
        "        max_class_index = -1\n",
        "        class_sum = 0\n",
        "        for c in range(5, C + 5):\n",
        "          class_value = math.exp(bb_box[c])\n",
        "          if class_value >= max_class:\n",
        "            max_class = class_value\n",
        "            max_class_index = c - 5\n",
        "\n",
        "          class_sum +=  class_value\n",
        "\n",
        "        real_x = (i + x)*56 - (w*IMG_WIDTH) / 2\n",
        "        real_x = real_x if real_x > 0 else 0\n",
        "        real_y = (j + y)*56 - (h*IMG_HEIGHT) / 2\n",
        "        real_y = real_y if real_y > 0 else 0\n",
        "        bb_boxes.append({\n",
        "            'x': real_x,\n",
        "            'y': real_y,\n",
        "            'w': w * IMG_WIDTH,\n",
        "            'h': h * IMG_HEIGHT,\n",
        "            'confidence': confidence,\n",
        "            'class': CLASS_LABELS[max_class_index],\n",
        "            'class_probability': max_class / class_sum\n",
        "        })\n",
        "  return bb_boxes\n",
        "\n",
        "\n",
        "result = model.predict(np.array([image_batch[0]]))\n",
        "xs, ys, ws, hs = get_label_bounding_boxes(label_batch[0])                \n",
        "bb_boxes = get_predicted_bounding_boxes(result)\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(image_batch[0])\n",
        "\n",
        "for j in range(len(xs)):\n",
        "    rect1 = patches.Rectangle((xs[j], ys[j]),ws[j],hs[j],linewidth=1,edgecolor='r',facecolor='none')\n",
        "    ax.add_patch(rect1)\n",
        "\n",
        "bb_boxes.sort(key=lambda x: x['class_probability'], reverse=True)\n",
        "bb_boxes = bb_boxes[:10]\n",
        "bb_boxes.sort(key=lambda x: x['confidence'] * x['class_probability'], reverse=True)\n",
        "for index, color in enumerate(['y', 'g', 'b', 'b', 'g', 'g', 'b', 'y', 'b']):\n",
        "    width = bb_boxes[index]['w'] if bb_boxes[index]['w'] + bb_boxes[index]['x'] < 224 else 224\n",
        "    height = bb_boxes[index]['h'] if bb_boxes[index]['h'] + bb_boxes[index]['y'] < 224 else 224\n",
        "    rect = patches.Rectangle((bb_boxes[index]['x'],bb_boxes[index]['y']),width,height,linewidth=1,edgecolor=color,facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "    print('CLASS: ' + bb_boxes[index][\"class\"] + ' Color: ' + color + ' Prob: ' + str(bb_boxes[index][\"class_probability\"]) + ' Confidence: ' + str(bb_boxes[index][\"confidence\"]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}