{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzNWD_0Dy_1Z"
   },
   "source": [
    "# Prepare the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNuzY6kSy8XN"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget https://github.com/aleksandar-aleksandrov/groceries-object-detection-dataset/archive/master.zip\n",
    "\n",
    "# Download annotations\n",
    "!7z x -y master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OP03RWVpc0il"
   },
   "outputs": [],
   "source": [
    "!cd groceries-object-detection-dataset-master\n",
    "!ls\n",
    "!ls groceries-object-detection-dataset-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDO21stNNm2C"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjhJcgDLzgl3"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Reshape, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ms6uqbtFIfqt"
   },
   "outputs": [],
   "source": [
    "# Define global Variables\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "TRAIN_DATASET_SIZE = 4960\n",
    "CHANNELS = 3\n",
    "EPOCHS = 800\n",
    "\n",
    "# The image is divided into 4x4 grid of cells\n",
    "S = 4\n",
    "# Amount of Bounding Boxes. Each BB is a tuple of type (x, y, w, h, confidence)\n",
    "B = 1\n",
    "B_SIZE = 5\n",
    "\n",
    "# Class Labels\n",
    "CLASS_LABELS = [\n",
    "    'beans', 'cake', 'candy', 'cereal', 'chips', 'chocolate', 'coffee', 'corn',\n",
    "    'fish', 'flour', 'honey', 'jam', 'juice', 'milk', 'nuts', 'oil', 'pasta',\n",
    "    'rice', 'soda', 'spices', 'sugar', 'tea', 'tomato_sauce', 'vinegar', 'water'\n",
    "]\n",
    "\n",
    "C = len(CLASS_LABELS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCS7RPmozE5H"
   },
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCcfCMCTGot5"
   },
   "outputs": [],
   "source": [
    "def get_objects(file):\n",
    "    root = ET.parse(file).getroot()\n",
    "\n",
    "    objs = []\n",
    "    for child in root.iter('object'):\n",
    "        obj = {}\n",
    "        obj['class'] = child.find('name').text\n",
    "        \n",
    "        bndbox = child.find('bndbox')\n",
    "        obj['xmax'] = float(bndbox.find('xmax').text)\n",
    "        obj['xmin'] = float(bndbox.find('xmin').text)\n",
    "        obj['ymax'] = float(bndbox.find('ymax').text)\n",
    "        obj['ymin'] = float(bndbox.find('ymin').text)\n",
    "\n",
    "        objs.append(obj)\n",
    "\n",
    "    return objs\n",
    "\n",
    "def load_dataset(dataset_size):\n",
    "    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    X = np.zeros((dataset_size, IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
    "    Y = np.zeros((dataset_size, S, S, B, 5 + C))\n",
    "\n",
    "    index = 0\n",
    "    labels_path = Path(f'/content/groceries-object-detection-dataset-master/dataset/annotations')\n",
    "    img_path = Path(f'/content/groceries-object-detection-dataset-master/dataset/images')\n",
    "\n",
    "    for class_dir in labels_path.iterdir():\n",
    "        for file in class_dir.iterdir():\n",
    "            objects = get_objects(file)\n",
    "            array = np.zeros((S, S, B, 5 + C))\n",
    "            \n",
    "            for obj in objects:\n",
    "                confidence = 1\n",
    "\n",
    "                center_x = .5*(obj['xmin'] + obj['xmax'])\n",
    "                center_x = center_x / (IMG_HEIGHT / S)\n",
    "                x = center_x - np.floor(center_x)\n",
    "                grid_x = int(np.floor(center_x))\n",
    "\n",
    "                center_y = .5*(obj['ymin'] + obj['ymax'])\n",
    "                center_y = center_y / (IMG_WIDTH / S)\n",
    "                y = center_y - np.floor(center_y)\n",
    "                grid_y = int(np.floor(center_y))\n",
    "\n",
    "                w = (obj['xmax'] - obj['xmin']) / IMG_HEIGHT\n",
    "                h = (obj['ymax'] - obj['ymin']) / IMG_WIDTH\n",
    "\n",
    "                class_array = [0.] * C\n",
    "                class_array[CLASS_LABELS.index(obj['class'])] = 1.\n",
    "\n",
    "                array[grid_x, grid_y, 0] = [x] + [y] + [w] + [h] + [confidence] + class_array\n",
    "            img_paths = str(file).replace('annotations', 'images').replace('.xml', '.png')\n",
    "            img = tf.keras.preprocessing.image.load_img(img_paths)\n",
    "            img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            X[index] = img_arr\n",
    "            Y[index] = array\n",
    "            index += 1\n",
    "\n",
    "            if index >= dataset_size:\n",
    "                break\n",
    "        if index >= dataset_size:\n",
    "              break\n",
    "    Y = np.asarray(Y).astype('float32')\n",
    "    return image_generator.flow(X, Y, batch_size=BATCH_SIZE)\n",
    "                    \n",
    "def show_batch(dataset):\n",
    "        image_batch, label_batch = next(dataset)\n",
    "        image_batch = list(image_batch)\n",
    "        label_batch = list(label_batch)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for n in range(4):\n",
    "            ax = plt.subplot(2, 2, n + 1)\n",
    "            plt.imshow(image_batch[n])\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "train_dataset = load_dataset(TRAIN_DATASET_SIZE)\n",
    "show_batch(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZzDS2G_zIuQ"
   },
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BoKwjA5-1KZD"
   },
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    return tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), classes=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yGSFqOM1dlj"
   },
   "outputs": [],
   "source": [
    "def freeze_trained_layers(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "        \n",
    "    return model\n",
    "\n",
    "def get_yolo_model():\n",
    "    base_model = get_base_model()\n",
    "    base_model = freeze_trained_layers(base_model)\n",
    "\n",
    "    x = Conv2D(B * (5 + C), (3,3), strides=(2,2), padding='same', kernel_initializer='lecun_normal')(base_model.output)\n",
    "    x = Conv2D(B * (5 + C), (1,1), strides=(1,1), padding='same', kernel_initializer='lecun_normal')(x)\n",
    "    x = Reshape((S, S, B, 5 + C))(x)\n",
    "\n",
    "    return Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioJaMQSOzOiw"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YYqeBKKQduJ"
   },
   "outputs": [],
   "source": [
    "def yolo_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "        \n",
    "    cell_x = tf.cast(tf.reshape(tf.tile(tf.range(S), [S]), (1, S, S, 1, 1)), dtype=tf.float32)\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, B, 1])\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.sigmoid(y_pred[..., 2:4])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    #iou_scores = 1\n",
    "\n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    \n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1)\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = tf.expand_dims(true_box_xy, 4)\n",
    "    true_wh = tf.expand_dims(true_box_wh, 4)\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_wh_half\n",
    "    true_maxes   = true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "    \n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.cast(best_ious < 0.6,dtype=tf.float32) * (1 - y_true[..., 4]) * 0.5\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * 0.5\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_wt = tf.ones(C)\n",
    "    class_mask = y_true[..., 4] * tf.gather(class_wt, true_box_class) * 0.5       \n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.cast(coord_mask > 0.0,dtype=tf.float32))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.cast(conf_mask  > 0.0, dtype=tf.float32))\n",
    "    nb_class_box = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask) / (nb_conf_box + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class * 10\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwnUdck5sT0C"
   },
   "outputs": [],
   "source": [
    "model = get_yolo_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHUKTXZgJjCg"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=2e-4, momentum=0.9), loss=yolo_loss)\n",
    "\n",
    "history = model.fit(train_dataset, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--5wqBV8J-OG"
   },
   "source": [
    "# Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gZp6l6mKBp9"
   },
   "outputs": [],
   "source": [
    "# Function to visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    training_loss = history.history['loss']\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.legend(['Training Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJDZ7CyhzWkI"
   },
   "source": [
    "#Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBRfu4oPqQ_B"
   },
   "outputs": [],
   "source": [
    "# Convert to TFLite Format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vL5XOH4FwB1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download tflite model\n",
    "files.download('/content/converted_model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPm-iUUsOSU7"
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "tf.saved_model.save(model, \"/content/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6KIL8m9OuAF"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/model.zip /content/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLYAaIFPrCqw"
   },
   "outputs": [],
   "source": [
    "files.download('/content/model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--ni_FnnrC8k"
   },
   "outputs": [],
   "source": [
    "# Save the loss\n",
    "open(\"/content/history.txt\", \"w\").write(str(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnHrDXuafTjw"
   },
   "outputs": [],
   "source": [
    "files.download('/content/history.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hAWgbZGfo3-"
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2xzHRDB1frTz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "image_batch, label_batch = next(train_dataset)\n",
    "image_batch = list(image_batch)\n",
    "label_batch = list(label_batch)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def get_label_bounding_boxes(label):\n",
    "    x_a, y_a, w_a, h_a = 0, 0, 0, 0\n",
    "    xs, ys, ws, hs = [], [], [], []\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            for b in range(B):\n",
    "                bb_box = label[i][j][b]\n",
    "                \n",
    "                if bb_box[0] != 0:\n",
    "                    x_a = bb_box[0]\n",
    "                    y_a = bb_box[1]\n",
    "                    w_a = bb_box[2] * IMG_WIDTH\n",
    "                    h_a = bb_box[3] * IMG_HEIGHT\n",
    "                    \n",
    "                    x_a = (i + x_a)*56 - w_a / 2\n",
    "                    y_a = (j + y_a)*56 - h_a / 2\n",
    "                    xs.append(x_a)\n",
    "                    ys.append(y_a)\n",
    "                    ws.append(w_a)\n",
    "                    hs.append(h_a)\n",
    "    return xs, ys, ws, hs\n",
    "  \n",
    "def get_predicted_bounding_boxes(result):\n",
    "    bb_boxes = []\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "              for b in range(B):\n",
    "                bb_box = result[0][i][j][b]\n",
    "        \n",
    "                x = sigmoid(bb_box[0])\n",
    "                y = sigmoid(bb_box[1])\n",
    "                w = sigmoid(bb_box[2])\n",
    "                h = sigmoid(bb_box[3])\n",
    "\n",
    "                confidence = sigmoid(bb_box[4])\n",
    "\n",
    "                max_class = 0\n",
    "                max_class_index = -1\n",
    "                class_sum = 0\n",
    "                for c in range(5, C + 5):\n",
    "                    class_value = math.exp(bb_box[c])\n",
    "                    if class_value >= max_class:\n",
    "                        max_class = class_value\n",
    "                        max_class_index = c - 5\n",
    "\n",
    "                    class_sum +=  class_value\n",
    "\n",
    "                real_x = (i + x)*56 - (w*IMG_WIDTH) / 2\n",
    "                real_x = real_x if real_x > 0 else 0\n",
    "                real_y = (j + y)*56 - (h*IMG_HEIGHT) / 2\n",
    "                real_y = real_y if real_y > 0 else 0\n",
    "                bb_boxes.append({\n",
    "                    'x': real_x,\n",
    "                    'y': real_y,\n",
    "                    'w': w * IMG_WIDTH,\n",
    "                    'h': h * IMG_HEIGHT,\n",
    "                    'confidence': confidence,\n",
    "                    'class': CLASS_LABELS[max_class_index],\n",
    "                    'class_probability': max_class / class_sum\n",
    "                })\n",
    "    return bb_boxes\n",
    "\n",
    "\n",
    "result = model.predict(np.array([image_batch[0]]))\n",
    "xs, ys, ws, hs = get_label_bounding_boxes(label_batch[0])                \n",
    "bb_boxes = get_predicted_bounding_boxes(result)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_batch[0])\n",
    "\n",
    "for j in range(len(xs)):\n",
    "    rect1 = patches.Rectangle((xs[j], ys[j]),ws[j],hs[j],linewidth=1,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect1)\n",
    "\n",
    "bb_boxes.sort(key=lambda x: x['class_probability'], reverse=True)\n",
    "bb_boxes = bb_boxes[:10]\n",
    "bb_boxes.sort(key=lambda x: x['confidence'] * x['class_probability'], reverse=True)\n",
    "for index, color in enumerate(['y', 'g', 'b', 'b', 'g', 'g', 'b', 'y', 'b']):\n",
    "    width = bb_boxes[index]['w'] if bb_boxes[index]['w'] + bb_boxes[index]['x'] < 224 else 224\n",
    "    height = bb_boxes[index]['h'] if bb_boxes[index]['h'] + bb_boxes[index]['y'] < 224 else 224\n",
    "    rect = patches.Rectangle((bb_boxes[index]['x'],bb_boxes[index]['y']),width,height,linewidth=1,edgecolor=color,facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    print('CLASS: ' + bb_boxes[index][\"class\"] + ' Color: ' + color + ' Prob: ' + str(bb_boxes[index][\"class_probability\"]) + ' Confidence: ' + str(bb_boxes[index][\"confidence\"]))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RzNWD_0Dy_1Z",
    "OCS7RPmozE5H",
    "fZzDS2G_zIuQ",
    "ioJaMQSOzOiw",
    "--5wqBV8J-OG",
    "vJDZ7CyhzWkI",
    "0hAWgbZGfo3-"
   ],
   "name": "YOLO-Groceries.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
